---
title: "En la pr치ctica con Hugging Face"
description: "Como manipulas Imagenes-Datos de Ocean color derivados de un Satelite como Sentinel-3 ?"
lead: "Manos a la obra con 游뱅Hugging Face游뱅! una herramienta de 'transformadores' muy poderasa que nos ayuda a convertir texto (letras-palabras) a datos n칰mericos y poder analizarlo de diferentes formas."
date: 2020-10-06T08:49:31+00:00
lastmod: 2020-10-06T08:49:31+00:00
draft: false
images: []
menu:
  docs:
    parent: "reportes"
weight: 630
toc: true
---

## Resumen

El proposito es analizar los sentimientos de comentarios escritos por usuarios en una plataforma popular de viajes sobre su experiencia en playas tur칤sticas. 

El proceso consta basicamente de 3 pasos:

- Extracci칩n de comentarios en la plataforma de viajes escogida. A este proceso se le denomina "web scraping".

- Organizar los comentarios en una base de datos de facil manipulacion.

- Tokenizaci칩n de texto con Hugging Face游뱅. Se usa un Modelo BERT multilingue por lo que es posible trabajar con otros idiomas diferentes al espa침ol. El modelo ha sido entrenado en ingl칠s, aleman, holandes o frances, entre otros.


## Pre-requisitos

Para una mejor comprension del An치lisis de Sentimientos con Hugging Face y BERT, ayudar칤a tener nociones basicas de **Python** y de como trabajar en un Jupyter Notebook.

Este [游녤art칤culo.](https://grammaloreto.netlify.app/analisis-sent/) ilustra lo que vamos a hacer.

```bash
python --version # tienes python instalado?
```

## 1. Web Scraping de comentarios
Para extraer los comentarios de las playas en la plataforma de viajes escogida, se va a usar una libreria de **python** llamada *Beatiful Soup*. 

Como se mencion칩 en los pre-requisitos se trabajar치 en un **Jupyter notebook**, el cual es un entorno inform치tico que soporta python para correr codigo por m칩dulos. 

Estan son las librerias para el "web scraping":

```bash
from bs4 import BeautifulSoup
import requests
import re
```

**Request** es una librer칤a que permite hacer solicitudes HTTP para interactuar y "consumir" datos de la web. En el parentesis va una URL o direccion del sitio web donde est치n los comentarios.

```bash
data = requests.get("https://www.tripadvisor.co/Attraction_Review-g297482-d1024602-Reviews-Johnny_Cay-San_Andres_Island_San_Andres_and_Providencia_Department.html")
```

A continuacion entra a trabajar **beautiful soup** tomando el codigo *html* de la web escogida y atrapando s칩lo las etiquetas que se le indican. 

```bash
soup = BeautifulSoup(data.text, 'html.parser')
for div in soup.find_all("div"):
    regex = re.compile('.*pIRBV.*')
    results = soup.find_all('div',{'class':regex})
    reviews = [result.text for result in results]
```

Despues de estas pocas lineas de codigo son extraidos todos los comentarios de la url indicada. Para confirmar, llame a los reviews y aparecer치n.

```bash
reviews
```

## 2. Base de Datos (df)

Teniendo todos los comentarios en la variable *reviews* lo siguiente ser치 agrupar/ordenar los comentarios en una Base de Datos (data frame).

Para este paso se usan 2 de las librerias mas populares de **python:** **pandas** y **numpy**.

```bash
import pandas as pd
import numpy as np
```

Con una simple linea de c칩digo quedar치n todos los *reviews* en un df (data frame o base de datos).

```bash
df = pd.DataFrame(np.array(reviews), columns=['review'])
```

## 3. Tokenizaci칩n de Palabras

Para tokenizar o asignarle un valor numerico a cada palabra que conforma un comentario es que utilizamos Hugging Face y los transformadores.

Para poder usar esta biblioteca es necesario instalarla primero en el notebook o en el ambiente con el que se est치 trabajando.

```bash
!pip install transformers 
```

Una vez instalado Hugging Face (transformadores) se pueden llamar los m칩dulos de "tokenizaci칩n".

>De igual forma se usa PyTorch, para una mejor experiencia con los transformadores.

```bash
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
```
### Modelo Clasificaci칩n de Texto

Hay modelos en muchos idiomas, entrenados con distintos tipos de datos. [Modelos de Clasificacion de Texto en Hugging Face.](https://huggingface.co/models?pipeline_tag=text-classification&sort=downloads)

El Modelo escogido es un BERT multilingue de nlptown entrenado con comentarios calificados de 1-5. Por este motivo nuestro analisis de sentimientos de playas tendr치 una calificacion igual, de 1-5, donde 1-2 son malas experiencias, 3 neutral y 4-5 buenas experiencias.

De esta forma se incorpora el modelo BERT de nlptown a nuestro an치lisis:

```bash
tokenizer = AutoTokenizer.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")

model = AutoModelForSequenceClassification.from_pretrained("nlptown/bert-base-multilingual-uncased-sentiment")
```

Ahora s칤 es momento de tokenizar los *reviews*:

```bash
result = model(tokens)
def sentiment_score(review):
    tokens = tokenizer.encode(review, return_tensors='pt')
    result = model(tokens)
    return int(torch.argmax(result.logits))+1
```

Al correr la funci칩n anterior se podr치 usar sobre nuestra base de datos! 

Lo siguiente ser치 adicionar una columna nueva a la df llamada **sentiment** que es donde ir치 la calificacion (1-5) de cada playa. Esta columan aplica el codigo anterior (sentiment-score) en base a una funci칩n lambda especificada.

```bash
df['sentiment'] = df['review'].apply(lambda x: sentiment_score(x[:512]))
```

El resultado final es una base de datos (df) con 2 columnas: la primera con los reviews o comentarios extraidos y la segunda llamada 'sentiment' con la calificaci칩n de 1 a 5 o "sentimiento" de los usuario sobre las playas.

Para una mejor comprensi칩n de los resultados obtenidos en la columna 'sentiment' se puede realizar estadistica descriptiva basica (histogramas, medias, promedios etc) con *pandas* o *numpy* y as칤 tener un mejor panorama de las opiniones y sentimientos asociados a las playas.

Si desea profundizar con algunos analisis de sentimientos hechos previamente de playas Latinoamericas, puede revisar este [repositorio de GitHub.](https://github.com/grammaloreto/BeachSentimentAnalysis)






































